import { allProviderModelData, allProviderEmbeddingData } from "@/app/providers/provider";
import { ALL_LORA_PROVIDERS } from "@/app/lora-providers/lora-provider";
import { formatPrice } from "@/app/(sidebar)/billing/usage-based/price-data-layer";
import { formatK } from "@/app/(sidebar)/billing/usage-based/money";
import { ModelTable } from "@/app/pricing/model-tables";
import { flags } from "@/app/feature-flags";
import { currentUser } from "@clerk/nextjs/server";
import { APP_BASE_URL } from "@/app/conf";
import { LoRATooltip } from "@/app/pricing/pricing-client";
import { Anchor, Em } from "@/app/components/typography";
import { SubdomainLink } from "@/app/components/subdomain-link";
import { Alert, AlertTitle, AlertDescription } from "@/app/components/ui/alert";
import { InfoIcon } from "lucide-react";

export const metadata = {
  title: "Models",
};

export function caselessNameSort(a, b) {
  if(a.name.toLowerCase() < b.name.toLowerCase()) return -1;
  if(a.name.toLowerCase() > b.name.toLowerCase()) return 1;
  return 0;
}

export const proxiedModels = allProviderModelData().map(model => ({
  name: model.name,
  formattedContextLength: formatK(model.contextLength),
  provider: model.userFacingProvider,
})).sort(caselessNameSort);

export const multiloraBaseModels = ALL_LORA_PROVIDERS.flatMap(provider => {
  return Object.entries(provider.baseModels).map(([ baseModel, priceDef ]) => {
    return {
      name: baseModel,
      formattedContextLength: formatK(priceDef.contextLength),
      provider: provider.userFacingName,
    };
  });
});

export const embeddingModels = allProviderEmbeddingData().map(model => ({
  name: model.name,
  formattedContextLength: formatK(model.contextLength),
  url: `https://huggingface.co/${model.name}`,
  provider: model.userFacingProvider,
})).sort(caselessNameSort);

# Available Models

<Alert className="mb-4">
  <InfoIcon color="#00bb00" />
  <AlertTitle>Subscriptions</AlertTitle>
  <AlertDescription>
    <p><strong>Always-On</strong>, <strong>LoRA</strong>, and <strong>Embeddings</strong> models are included in every <SubdomainLink href="/billing/"><strong>subscription</strong></SubdomainLink>.</p>
  </AlertDescription>
</Alert>

## Always-On Models

These models are included in all Standard and Pro <SubdomainLink href="/billing/">subscriptions</SubdomainLink>.
Per-token pricing is also available with <Anchor href="/pricing">usage-based billing</Anchor>.

<Alert className="mb-4">
  <InfoIcon color="#00bb00" />
  <AlertTitle>Full model intelligence</AlertTitle>
  <AlertDescription>
    <p>For our self-hosted <Em>Synthetic</Em> models, we run the weights directly and do not perform any quantization on either the weights or the KV cache.</p>
  </AlertDescription>
</Alert>

<ModelTable
  className="mb-6"
  models={proxiedModels}
  linkToModel={true}
  appBaseUrl={APP_BASE_URL}
  showHfPrefix={true}
  showCopyButton={true}
  showProvider={true}
/>

## LoRA Models

<LoRATooltip className="mb-4" infoColor="#00bb00" />

We support LoRAs for the following base models:

<ModelTable
  className="mb-6"
  models={multiloraBaseModels}
  modelHeader="Base Model"
  appBaseUrl={APP_BASE_URL}
  showProvider={true}
/>

## Embedding Models

Embedding models convert text into numerical vectors for search, clustering, and other applications.

There's no additional charge for using embeddings, and embeddings requests don't count against your subscription rate limit.

<ModelTable
  className="mb-6"
  models={embeddingModels}
  linkToModel={true}
  appBaseUrl={APP_BASE_URL}
  showHfPrefix={true}
  showCopyButton={true}
  showProvider={true}
/>

## Getting Started

Ready to start using our models? Check out:

- [**Getting Started Guide**](/docs/api/getting-started) - Your first API call
- [**chat/completions**](/docs/openai/chat-completions) - Most popular endpoint for conversations

Need help choosing the right model? Join our <SubdomainLink href="/discord">Discord community</SubdomainLink> for recommendations!
